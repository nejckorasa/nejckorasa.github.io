<!doctype html><html lang=en dir=auto data-theme=auto><head><meta charset=utf-8><meta http-equiv=X-UA-Compatible content="IE=edge"><meta name=viewport content="width=device-width,initial-scale=1,shrink-to-fit=no"><meta name=robots content="index, follow"><title>Posts | Nejc Korasa</title><meta name=keywords content><meta name=description content="Posts - Nejc Korasa"><meta name=author content="Nejc Korasa"><link rel=canonical href=https://nejckorasa.github.io/posts/><meta name=google-site-verification content="G-R86690PBWG"><link crossorigin=anonymous href=/assets/css/stylesheet.343cc480b9ffc8f04ccbe5e968ad674880cab773ec19905e93033065c1e7a804.css integrity="sha256-NDzEgLn/yPBMy+XpaK1nSIDKt3PsGZBekwMwZcHnqAQ=" rel="preload stylesheet" as=style><link rel=icon href=https://nejckorasa.github.io/favicon.ico><link rel=icon type=image/png sizes=16x16 href=https://nejckorasa.github.io/favicon-16x16.png><link rel=icon type=image/png sizes=32x32 href=https://nejckorasa.github.io/favicon-32x32.png><link rel=apple-touch-icon href=https://nejckorasa.github.io/apple-touch-icon.png><link rel=mask-icon href=https://nejckorasa.github.io/safari-pinned-tab.svg><meta name=theme-color content="#2e2e33"><meta name=msapplication-TileColor content="#2e2e33"><link rel=alternate type=application/rss+xml href=https://nejckorasa.github.io/posts/index.xml title=rss><link rel=alternate hreflang=en href=https://nejckorasa.github.io/posts/><noscript><style>#theme-toggle,.top-link{display:none}</style><style>@media(prefers-color-scheme:dark){:root{--theme:rgb(29, 30, 32);--entry:rgb(46, 46, 51);--primary:rgb(218, 218, 219);--secondary:rgb(155, 156, 157);--tertiary:rgb(65, 66, 68);--content:rgb(196, 196, 197);--code-block-bg:rgb(46, 46, 51);--code-bg:rgb(55, 56, 62);--border:rgb(51, 51, 51);color-scheme:dark}.list{background:var(--theme)}.toc{background:var(--entry)}}@media(prefers-color-scheme:light){.list::-webkit-scrollbar-thumb{border-color:var(--code-bg)}}</style></noscript><script>localStorage.getItem("pref-theme")==="dark"?document.querySelector("html").dataset.theme="dark":localStorage.getItem("pref-theme")==="light"?document.querySelector("html").dataset.theme="light":window.matchMedia("(prefers-color-scheme: dark)").matches?document.querySelector("html").dataset.theme="dark":document.querySelector("html").dataset.theme="light"</script><script async src="https://www.googletagmanager.com/gtag/js?id=G-R86690PBWG"></script><script>var doNotTrack=!1,dnt=navigator.doNotTrack||window.doNotTrack||navigator.msDoNotTrack,doNotTrack=dnt=="1"||dnt=="yes";if(!doNotTrack){window.dataLayer=window.dataLayer||[];function gtag(){dataLayer.push(arguments)}gtag("js",new Date),gtag("config","G-R86690PBWG")}</script><meta property="og:url" content="https://nejckorasa.github.io/posts/"><meta property="og:site_name" content="Nejc Korasa"><meta property="og:title" content="Posts"><meta property="og:description" content="Nejc Korasa"><meta property="og:locale" content="en-us"><meta property="og:type" content="website"><meta property="og:image" content="https://avatars.githubusercontent.com/nejckorasa"><meta name=twitter:card content="summary_large_image"><meta name=twitter:image content="https://avatars.githubusercontent.com/nejckorasa"><meta name=twitter:title content="Posts"><meta name=twitter:description content="Nejc Korasa"><script type=application/ld+json>{"@context":"https://schema.org","@type":"BreadcrumbList","itemListElement":[{"@type":"ListItem","position":1,"name":"Posts","item":"https://nejckorasa.github.io/posts/"}]}</script></head><body class=list id=top><header class=header><nav class=nav><div class=logo><a href=https://nejckorasa.github.io/ accesskey=h title="Nejc Korasa (Alt + H)">Nejc Korasa</a><div class=logo-switches><button id=theme-toggle accesskey=t title="(Alt + T)" aria-label="Toggle theme">
<svg id="moon" width="24" height="18" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><path d="M21 12.79A9 9 0 1111.21 3 7 7 0 0021 12.79z"/></svg>
<svg id="sun" width="24" height="18" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><circle cx="12" cy="12" r="5"/><line x1="12" y1="1" x2="12" y2="3"/><line x1="12" y1="21" x2="12" y2="23"/><line x1="4.22" y1="4.22" x2="5.64" y2="5.64"/><line x1="18.36" y1="18.36" x2="19.78" y2="19.78"/><line x1="1" y1="12" x2="3" y2="12"/><line x1="21" y1="12" x2="23" y2="12"/><line x1="4.22" y1="19.78" x2="5.64" y2="18.36"/><line x1="18.36" y1="5.64" x2="19.78" y2="4.22"/></svg></button></div></div><ul id=menu><li><a href=https://nejckorasa.github.io/archives/ title=Archive><span>Archive</span></a></li><li><a href=https://nejckorasa.github.io/categories/ title=Categories><span>Categories</span></a></li><li><a href=https://nejckorasa.github.io/tags/ title=Tags><span>Tags</span></a></li><li><a href=https://nejckorasa.github.io/search/ title="Search (Alt + /)" accesskey=/><span>Search</span></a></li></ul></nav></header><main class=main><header class=page-header><div class=breadcrumbs><a href=https://nejckorasa.github.io/>Home</a></div><h1>Posts
<a href=/posts/index.xml title=RSS aria-label=RSS><svg viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" height="23"><path d="M4 11a9 9 0 019 9"/><path d="M4 4a16 16 0 0116 16"/><circle cx="5" cy="19" r="1"/></svg></a></h1></header><article class=post-entry><header class=entry-header><h2 class=entry-hint-parent>Kafka Backfill Playbook: Accessing Historical Data</h2></header><div class=entry-content><p>Event-driven architectures with Kafka have become a standard way of building modern microservices. At first, everything works smoothly - services communicate via events, state is rebuilt from event streams, and the system scales well. But as your data grows, you face an inevitable challenge: what happens when you need to access historical events that are no longer in Kafka?
1. The Problem: Finite Retention & The Need for Backfills In a perfect world, we would keep every event log in Kafka forever. In the real world, however, storing an ever-growing history on high-performance broker disks is prohibitively expensive.
...</p></div><footer class=entry-footer><span title='2025-09-25 00:00:00 +0000 UTC'>September 25, 2025</span>&nbsp;·&nbsp;<span>8 min</span>&nbsp;·&nbsp;<span>1594 words</span>&nbsp;·&nbsp;<span>Nejc Korasa</span></footer><a class=entry-link aria-label="post link to Kafka Backfill Playbook: Accessing Historical Data" href=https://nejckorasa.github.io/posts/kafka-backfill/></a></article><article class=post-entry><header class=entry-header><h2 class=entry-hint-parent>Data Oriented Programming (DOP) in Java</h2></header><div class=entry-content><p>What is Data Oriented Programming? Data Oriented Programming (DOP) is gaining momentum in the Java ecosystem due to recent language features streamlining its adoption. While conceptually straightforward, DOP offers significant advantages. But what is it?
How do we build our objects? Where does the state go? Where does the behavior go? OOO encourages us to bundle state and behavior together. But what if we separated this? What if data became the primary focus, with logic completely separated? This is the central idea of Data Oriented Programming (DOP), simple.
...</p></div><footer class=entry-footer><span title='2025-04-18 00:00:00 +0000 UTC'>April 18, 2025</span>&nbsp;·&nbsp;<span>6 min</span>&nbsp;·&nbsp;<span>1177 words</span>&nbsp;·&nbsp;<span>Nejc Korasa</span></footer><a class=entry-link aria-label="post link to Data Oriented Programming (DOP) in Java" href=https://nejckorasa.github.io/posts/data-oriented-programming-in-java/></a></article><article class=post-entry><header class=entry-header><h2 class=entry-hint-parent>Idempotent Processing with Kafka</h2></header><div class=entry-content><p>Duplicate Messages are Inevitable Duplicate messages are an inherent aspect of message-based systems and can occur for various reasons. In the context of Kafka, it is essential to ensure that your application is able to handle these duplicates effectively. As a Kafka consumer, there are several scenarios that can lead to the consumption of duplicate messages:
There can be an actual duplicate message in the kafka topic you are consuming from. The consumer is reading 2 different messages that should be treated as duplicates. You consume the same message more than once due to various error scenarios that can happen, either in your application, or in the communication with a Kafka broker. To ensure the idempotent processing and handle these scenarios, it’s important to have a proper strategy to detect and handle duplicate messages.
...</p></div><footer class=entry-footer><span title='2023-02-04 00:00:00 +0000 UTC'>February 4, 2023</span>&nbsp;·&nbsp;<span>11 min</span>&nbsp;·&nbsp;<span>2210 words</span>&nbsp;·&nbsp;<span>Nejc Korasa</span></footer><a class=entry-link aria-label="post link to Idempotent Processing with Kafka" href=https://nejckorasa.github.io/posts/idempotent-kafka-procesing/></a></article><article class=post-entry><header class=entry-header><h2 class=entry-hint-parent>Avoid Tight Coupling of Tests to Implementation Details</h2></header><div class=entry-content><p>Building backend systems today will likely involve building many small, independent services that communicate and coordinate with one another to form a distributed system. While there are many resources available discussing the pros and cons of microservices, the architecture, and when it is appropriate to use, I want to focus on the functional testing of microservices and how it differs from traditional approaches.
In my experience, the “best testing practices” have evolved with the introduction of microservices, and traditional testing pyramids may not be the most effective or even potentially harmful in this context. In my work on various projects and companies, including the development of new digital banks and the migration of older systems to microservices as they scale, I have often encountered disagreements about the most appropriate testing strategies for microservices.
...</p></div><footer class=entry-footer><span title='2023-01-08 00:00:00 +0000 UTC'>January 8, 2023</span>&nbsp;·&nbsp;<span>5 min</span>&nbsp;·&nbsp;<span>995 words</span>&nbsp;·&nbsp;<span>Nejc Korasa</span></footer><a class=entry-link aria-label="post link to Avoid Tight Coupling of Tests to Implementation Details" href=https://nejckorasa.github.io/posts/microservice-testing/></a></article><article class=post-entry><header class=entry-header><h2 class=entry-hint-parent>Stream unzip files in S3 with Java</h2></header><div class=entry-content><p>I’ve been spending a lot of time with AWS S3 recently building data pipelines and have encountered a surprisingly non-trivial challenge of unzipping files in an S3 bucket. A few minutes with Google and StackOverflow made it clear many others have faced the same issue.
I’ll explain a few options to handle the unzipping as well as the end solution which has led me to build nejckorasa/s3-stream-unzip.
To sum up:
there is no support to unzip files in S3 in-line, there also is no unzip built-in api available in AWS SDK. In order to unzip you therefore need to download the files from S3, unzip and upload decompressed files back.
...</p></div><footer class=entry-footer><span title='2022-10-22 00:00:00 +0000 UTC'>October 22, 2022</span>&nbsp;·&nbsp;<span>4 min</span>&nbsp;·&nbsp;<span>761 words</span>&nbsp;·&nbsp;<span>Nejc Korasa</span></footer><a class=entry-link aria-label="post link to Stream unzip files in S3 with Java" href=https://nejckorasa.github.io/posts/s3-unzip/></a></article></main><footer class=footer><span>&copy; 2026 <a href=https://nejckorasa.github.io/>Nejc Korasa</a></span> ·
<span>Powered by
<a href=https://gohugo.io/ rel="noopener noreferrer" target=_blank>Hugo</a> &
<a href=https://github.com/adityatelange/hugo-PaperMod/ rel=noopener target=_blank>PaperMod</a></span></footer><a href=#top aria-label="go to top" title="Go to Top (Alt + G)" class=top-link id=top-link accesskey=g><svg viewBox="0 0 12 6" fill="currentColor"><path d="M12 6H0l6-6z"/></svg>
</a><script>let menu=document.getElementById("menu");if(menu){const e=localStorage.getItem("menu-scroll-position");e&&(menu.scrollLeft=parseInt(e,10)),menu.onscroll=function(){localStorage.setItem("menu-scroll-position",menu.scrollLeft)}}document.querySelectorAll('a[href^="#"]').forEach(e=>{e.addEventListener("click",function(e){e.preventDefault();var t=this.getAttribute("href").substr(1);window.matchMedia("(prefers-reduced-motion: reduce)").matches?document.querySelector(`[id='${decodeURIComponent(t)}']`).scrollIntoView():document.querySelector(`[id='${decodeURIComponent(t)}']`).scrollIntoView({behavior:"smooth"}),t==="top"?history.replaceState(null,null," "):history.pushState(null,null,`#${t}`)})})</script><script>var mybutton=document.getElementById("top-link");window.onscroll=function(){document.body.scrollTop>800||document.documentElement.scrollTop>800?(mybutton.style.visibility="visible",mybutton.style.opacity="1"):(mybutton.style.visibility="hidden",mybutton.style.opacity="0")}</script><script>document.getElementById("theme-toggle").addEventListener("click",()=>{const e=document.querySelector("html");e.dataset.theme==="dark"?(e.dataset.theme="light",localStorage.setItem("pref-theme","light")):(e.dataset.theme="dark",localStorage.setItem("pref-theme","dark"))})</script></body></html>