<!doctype html><html lang=en dir=auto><head><meta charset=utf-8><meta http-equiv=x-ua-compatible content="IE=edge"><meta name=viewport content="width=device-width,initial-scale=1,shrink-to-fit=no"><meta name=robots content="index, follow"><title>Idempotent Processing with Kafka | Nejc Korasa</title><meta name=keywords content="Kafka,Idempotency,Software Architecture,Event Driven Architecture,Asynchronous Processing,Transactional Outbox"><meta name=description content="Duplicate Messages are Inevitable Understanding the Intricacies of exactly-once semantics in Kafka Achieving Idempotent Processing with Kafka Idempotent Consumer Pattern Ordering of Messages Retry Handling Idempotent Processing and External Side Effects Publishing Output Messages to Kafka and Maintaining Data Consistency The Simplest Solution Transactional Outbox Pattern Without Transactional Outbox How it compares to Synchronous REST APIs Final Thoughts Duplicate Messages are Inevitable Duplicate messages are an inherent aspect of message-based systems and can occur for various reasons."><meta name=author content="Nejc Korasa"><link rel=canonical href=https://nejckorasa.github.io/posts/idempotent-kafka-procesing/><meta name=google-site-verification content="G-R86690PBWG"><link crossorigin=anonymous href=/assets/css/stylesheet.bccfefac377bc340f06c260aed1bddf49a4354816d7c570d6aac75a997986c95.css integrity="sha256-vM/vrDd7w0DwbCYK7Rvd9JpDVIFtfFcNaqx1qZeYbJU=" rel="preload stylesheet" as=style><script defer crossorigin=anonymous src=/assets/js/highlight.f413e19d0714851f6474e7ee9632408e58ac146fbdbe62747134bea2fa3415e0.js integrity="sha256-9BPhnQcUhR9kdOfuljJAjlisFG+9vmJ0cTS+ovo0FeA=" onload=hljs.initHighlightingOnLoad()></script>
<link rel=icon href=https://nejckorasa.github.io/favicon.ico><link rel=icon type=image/png sizes=16x16 href=https://nejckorasa.github.io/favicon-16x16.png><link rel=icon type=image/png sizes=32x32 href=https://nejckorasa.github.io/favicon-32x32.png><link rel=apple-touch-icon href=https://nejckorasa.github.io/apple-touch-icon.png><link rel=mask-icon href=https://nejckorasa.github.io/safari-pinned-tab.svg><meta name=theme-color content="#2e2e33"><meta name=msapplication-TileColor content="#2e2e33"><noscript><style>#theme-toggle,.top-link{display:none}</style><style>@media(prefers-color-scheme:dark){:root{--theme:rgb(29, 30, 32);--entry:rgb(46, 46, 51);--primary:rgb(218, 218, 219);--secondary:rgb(155, 156, 157);--tertiary:rgb(65, 66, 68);--content:rgb(196, 196, 197);--hljs-bg:rgb(46, 46, 51);--code-bg:rgb(55, 56, 62);--border:rgb(51, 51, 51)}.list{background:var(--theme)}.list:not(.dark)::-webkit-scrollbar-track{background:0 0}.list:not(.dark)::-webkit-scrollbar-thumb{border-color:var(--theme)}}</style></noscript><script async src="https://www.googletagmanager.com/gtag/js?id=G-R86690PBWG"></script>
<script>var doNotTrack=!1;if(!doNotTrack){window.dataLayer=window.dataLayer||[];function gtag(){dataLayer.push(arguments)}gtag("js",new Date),gtag("config","G-R86690PBWG",{anonymize_ip:!1})}</script><meta property="og:title" content="Idempotent Processing with Kafka"><meta property="og:description" content="Duplicate Messages are Inevitable Understanding the Intricacies of exactly-once semantics in Kafka Achieving Idempotent Processing with Kafka Idempotent Consumer Pattern Ordering of Messages Retry Handling Idempotent Processing and External Side Effects Publishing Output Messages to Kafka and Maintaining Data Consistency The Simplest Solution Transactional Outbox Pattern Without Transactional Outbox How it compares to Synchronous REST APIs Final Thoughts Duplicate Messages are Inevitable Duplicate messages are an inherent aspect of message-based systems and can occur for various reasons."><meta property="og:type" content="article"><meta property="og:url" content="https://nejckorasa.github.io/posts/idempotent-kafka-procesing/"><meta property="og:image" content="https://avatars.githubusercontent.com/nejckorasa"><meta property="article:section" content="posts"><meta property="article:published_time" content="2023-02-04T00:00:00+00:00"><meta property="article:modified_time" content="2023-02-04T00:00:00+00:00"><meta property="og:site_name" content="Nejc Korasa"><meta name=twitter:card content="summary_large_image"><meta name=twitter:image content="https://avatars.githubusercontent.com/nejckorasa"><meta name=twitter:title content="Idempotent Processing with Kafka"><meta name=twitter:description content="Duplicate Messages are Inevitable Understanding the Intricacies of exactly-once semantics in Kafka Achieving Idempotent Processing with Kafka Idempotent Consumer Pattern Ordering of Messages Retry Handling Idempotent Processing and External Side Effects Publishing Output Messages to Kafka and Maintaining Data Consistency The Simplest Solution Transactional Outbox Pattern Without Transactional Outbox How it compares to Synchronous REST APIs Final Thoughts Duplicate Messages are Inevitable Duplicate messages are an inherent aspect of message-based systems and can occur for various reasons."><script type=application/ld+json>{"@context":"https://schema.org","@type":"BreadcrumbList","itemListElement":[{"@type":"ListItem","position":2,"name":"Posts","item":"https://nejckorasa.github.io/posts/"},{"@type":"ListItem","position":3,"name":"Idempotent Processing with Kafka","item":"https://nejckorasa.github.io/posts/idempotent-kafka-procesing/"}]}</script><script type=application/ld+json>{"@context":"https://schema.org","@type":"BlogPosting","headline":"Idempotent Processing with Kafka","name":"Idempotent Processing with Kafka","description":"Duplicate Messages are Inevitable Understanding the Intricacies of exactly-once semantics in Kafka Achieving Idempotent Processing with Kafka Idempotent Consumer Pattern Ordering of Messages Retry Handling Idempotent Processing and External Side Effects Publishing Output Messages to Kafka and Maintaining Data Consistency The Simplest Solution Transactional Outbox Pattern Without Transactional Outbox How it compares to Synchronous REST APIs Final Thoughts Duplicate Messages are Inevitable Duplicate messages are an inherent aspect of message-based systems and can occur for various reasons.","keywords":["Kafka","Idempotency","Software Architecture","Event Driven Architecture","Asynchronous Processing","Transactional Outbox"],"articleBody":" Duplicate Messages are Inevitable Understanding the Intricacies of exactly-once semantics in Kafka Achieving Idempotent Processing with Kafka Idempotent Consumer Pattern Ordering of Messages Retry Handling Idempotent Processing and External Side Effects Publishing Output Messages to Kafka and Maintaining Data Consistency The Simplest Solution Transactional Outbox Pattern Without Transactional Outbox How it compares to Synchronous REST APIs Final Thoughts Duplicate Messages are Inevitable Duplicate messages are an inherent aspect of message-based systems and can occur for various reasons. In the context of Kafka, it is essential to ensure that your application is able to handle these duplicates effectively. As a Kafka consumer, there are several scenarios that can lead to the consumption of duplicate messages:\nThere can be an actual duplicate message in the kafka topic you are consuming from. The consumer is reading 2 different messages that should be treated as duplicates. You consume the same message more than once due to various error scenarios that can happen, either in your application, or in the communication with a Kafka broker. To ensure the idempotent processing and handle these scenarios, it’s important to have a proper strategy to detect and handle duplicate messages.\nUnderstanding the Intricacies of exactly-once semantics in Kafka Kafka offers different message delivery guarantees, or delivery semantics, between producers and consumers, namely at-least-once, at-most-once and exactly-once.\nExactly-once would seem like an obvious choice to guard against duplicate messages, but it not that simple and the devil is in the details. Confluent has spent a lot of resources to deliver exactly-once delivery guarantee, and you can read here on how it works in detail. It requires enabling specific Kafka features (i.e. Idempotent Producer and Kafka Transactions).\nFirst of all, it is only applicable in an application that consumes a Kafka message, does some processing, and writes a resulting message to a Kafka topic. Exactly-once messaging semantics ensures the combined outcome of multiple steps will happen exactly-once. Key word here is combined. A message will be consumed, processed, and resulting messages produced, exactly-once.\nCritical points to understand about exactly-once delivery are:\nAll other actions occurring as part of the processing can still happen multiple times, if the original message is re-consumed.\nThe guarantee only covers resulting messages from the processing to be written exactly once, so downstream transaction aware consumers will not have to handle duplicates. Hence, each individual action (internal or external) still needs to be processed in an idempotent fashion to ensure real end-to-end exactly once processing. Application may need to, for example, perform REST calls to other applications, write to the database etc.\nAll participating consumers and producers need to be configured correctly.\nKafka exactly-once semantics is achieved by enabling Kafka Idempotent Producers and Kafka Transactions in all consumers and producers involved. That includes the upstream producer and downstream consumers from the perspective of you application.\nIf you are using Event-driven architecture to implement inter-service communication in your system, it is likely that you will consume messages you don’t control, or own. Kafka topic is just your asynchronous API you are a consumer of. The topic and the producer can be owned by another team or a 3rd party. Similarly, you may not control downstream consumers.\nTo add to the first point, outbound messages can still be written to the topic multiple times before being successfully committed, it is the responsibility of any downstream consumers to only read committed messages (i.e. be transaction aware) in order to meet the exactly-once guarantee.\nit comes with a performance impact.\nExactly-once delivery comes with a performance overhead. There are simply more steps involved for a single kafka message to be processed (e.g. Kafka performs a two-phase commit to support transactions) and that results in lower throughput and increased latency.\nIn practice, it’s often much simpler, and more common, to settle for at-least-once semantic and just de-duplicate messages on the consumer side. Especially in cases where application processing is either expensive, or more involved and consists of other actions (e.g. REST calls and DB writes). It’s important to remember there is a transaction boundary gap between a DB transaction and a Kafka transaction, more on that later.\nAchieving Idempotent Processing with Kafka This will depend on the nature of processing, and on the shape of the output. To enable idempotent processing, the trigger for the processing - whether it be a Kafka message or an HTTP request - must carry a unique identifier (i.e. an idempotency key).\nIdempotent Consumer Pattern An Idempotent Consumer Pattern ensures that a Kafka consumer can handle duplicate messages correctly. Consumer can be made idempotent by recording in the database the IDs of the messages that it has processed successfully. When processing a message, a consumer can detect and discard duplicates by querying the database. To illustrate that with pseudocode:\nvar kafkaMessage = kafkaConsumer.consume(); if (!database.isDuplicate(kafkaMessage)) { var result = processMessageIdempotently(kafkaMessage); database.updateAndRecordProcessed(result); } kafkaConsumer.commitOffset(kafkaMessage); Ordering of Messages Choosing an appropriate topic key can help to ensure ordering guarantees within the same Kafka partition. For example, if messages are being processed in the context of a customer, using a customer ID as the topic key will ensure that messages for any individual customer will always be processed in the correct order.\nRetry Handling Kafka’s offset commits can be used to create a “transaction boundary” (not to be confused with Kafka transactions mentioned before) for retrying message processing in case of failure. The same message can then be consumed again until the consumer offset is committed. Retry handling is a complex topic and various strategies can be employed depending on the specific requirements of the application. Confluent has written about Kafka Error Handling Patterns that can be used to handle retries in a Kafka-based application.\nIdempotent Processing and External Side Effects As mentioned before, there is no exactly-once guarantee for application processing. All actions occurring as part of the processing, and all external side effects, can still happen multiple times. For example, in case of REST calls to other services, calls themselves need to be idempotent, and the same idempotency key needs to be relayed over to those calls. Similarly, all database writes need to be idempotent.\nPublishing Output Messages to Kafka and Maintaining Data Consistency When it comes to publishing messages back to Kafka after processing is complete, the complexity increases. In a Microservices architecture, services along with updating their own local data store they often need to notify other services within the organization of changes that have occurred. This is where event-driven architecture shines, allowing individual services to publish changes as events to a Kafka topic that can be consumed by other services. But how can this be achieved in a way that ensures data consistency and enables idempotent processing?\nThe Simplest Solution Consuming from Kafka has a built-in retry mechanism. If the processing is naturally idempotent, deterministic, and does not interact with other services (i.e. all its state resides in Kafka), then the solution can be relatively simple:\nvar kafkaMessage = kafkaConsumer.consume(); var result = processMessageIdempotently(kafkaMessage); var kafkaOutputMessage = result.toKafkaOutputMessage(); kafkaProducer.produceAndFlush(kafkaOutputMessage); kafkaConsumer.commitOffset(kafkaMessage); Consume the message from a Kafka topic. Process the message. Publish the resulting message to a Kafka topic. Commit the consumer offset. This approach ensures data consistency and enables idempotent processing. It guarantees that at least one published message is produced for every consumed message.\nTo ensure at least-once delivery of published messages, it’s also necessary to ensure that the message is actually sent to the Kafka broker and that the Kafka producer has flushed its outgoing message queue.\nTransactional Outbox Pattern Another approach is to utilize Transactional Outbox Pattern which fills the gap between the database and Kafka transaction boundary by atomically updating both within the database transaction. The reason being that it is not possible to have a single transaction that spans the application’s database as well as Kafka.\nOne possible implementation of this pattern is to have an “outbox” table and instead of publishing resulting messages directly to Kafka, the messages are written to the outbox table in a compatible format (e.g. Avro).\nvar kafkaMessage = kafkaConsumer.consume(); if (!database.isDuplicate(kafkaMessage)) { var result = processMessageIdempotently(kafkaMessage); var transaction = database.startTransaction(); database.updateAndRecordProcessed(result); database.writeOutbox(result); transaction.commit(); } kafkaConsumer.commitOffset(kafkaMessage); However, this pattern comes with additional complexity. The message must not only be written to the database but also published to Kafka. This can be implemented by a separate message relay service that continuously polls the database for new outbox messages, publishes them to Kafka, and marks them as processed. However, this approach has several drawbacks:\nIncreased load on the database: Frequently polling the database can cause a high level of read traffic, which can lead to increased load on the database and potentially slow down other processes that are trying to access it. Latency: Depending on the interval at which the database is polled, there may be a significant delay between when a message is added to the outbox and when it is published to Kafka. Scalability: If the number of messages to be published to Kafka increases, the rate of polling will need to be increased, which can further increase the load on the database and make the system less scalable. Schema incompatibility issues: If the message schema is incompatible with a destination topic, application processing will succeed, but the poller could be unable to publish a message to Kafka. The risk of this can be minimized by verifying Avro schema with a schema registry before writing to the outbox table. Ordering of messages: Poller needs to ensure the order of messages written to the outbox tables is retained when publishing to Kafka. Missed messages: There is a chance that a message is not picked up by the poller and not published to Kafka. Lack of real-time: The messages are not published to kafka in real-time as it depends on the polling interval. A better approach is to utilize CDC (change data capture) if your database supports it. You can use Debezium and Kafka Connect to integrate CDC with a PostgresDB for example. That way, the database and Kafka stay in sync, and you don’t have to deal with the drawbacks of database polling.\nWithout Transactional Outbox However, even with the use of CDC, that will still result in another component that needs to be managed and monitored, and another possible point of failure. In certain situations it is easier to avoid the Transactional Outbox Pattern and handle writes to Kafka within the application. That can be achieved by combining the first simple solution explained above with the Idempotent Consumer pattern:\nvar kafkaMessage = consumeKafkaMessage(kafkaClient); if (!database.isDuplicate(kafkaMessage)) { result = processMessageIdempotently(kafkaMessage); database.updateAndRecordProcessed(result); } else { result = database.readResult(kafkaMessage); } var kafkaOutputMessage = result.toKafkaOutputMessage(); kafkaProducer.produceAndFlush(kafkaOutputMessage); kafkaConsumer.commitOffset(kafkaMessage); Consume the message from a Kafka topic. Consult the database to confirm the message has not been previously processed. If it has, read the stored result and proceed to step 5. Process the message, taking care to handle any external actions in an idempotent manner. Write results to the database and mark the message as successfully processed. Publish the resulting message to a Kafka topic. Commit the consumer offset. The approach outlined above combines the use of the Idempotent Consumer pattern with direct publishing to Kafka, resulting in a streamlined solution for handling duplicate messages.\nAdditionally, by eliminating the need for an intermediate “outbox” table, this approach reduces the number of components that need to be managed and monitored, resulting in a simpler overall architecture.\nFurthermore, it also benefits from reduced latency in message publishing as it avoids the added step of writing to a database before publishing to Kafka.\nThis approach has some downsides to consider:\nIt might simplify overall architecture but it increases the complexity of processing within the application. The addition of a Kafka publish step can cause a performance overhead and prolong overall processing time. How it compares to Synchronous REST APIs Similarly to the Idempotent Consumer Pattern, in case of a REST API, received message IDs could also be tracked in a database to handle idempotency. However, there are drawbacks to using REST call as a trigger for processing, namely:\nThe retry strategy is out of the control of the application, and the caller is responsible for retrying the operation. That makes it more susceptible to failure scenarios and inconsistent states. There is no ordering guarantee when responding to HTTP calls, and additional care must be taken to avoid certain race conditions during processing. Publishing output messages to Kafka in a way that maintains data consistency can be achieved by using Transactional Outbox Pattern to atomically update the database and publish a message to Kafka.\nFinal Thoughts Kafka is an ideal platform for implementing idempotent processing in your application, and it offers several key advantages over traditional synchronous processing methods such as REST APIs. Its built-in retry mechanism and ordering guarantees are essential for ensuring idempotence and maintaining data consistency in the presence of failures.\nWhen it comes to message delivery guarantees, the exactly-once semantics offered by Kafka can be a powerful tool to guard against duplicate messages. However, it’s important to understand the intricacies of this feature, the requirements for its implementation, and its limitations. Additionally, the performance impact and complexity of exactly-once semantics should be taken into consideration.\nAchieving idempotent processing requires a thorough understanding of the triggers, actions, and outputs of the processing. Different approaches such as Idempotent Consumer Pattern and Transactional Outbox Pattern can be used to ensure that messages are processed correctly and that data consistency is maintained. It’s important to weigh the complexity and potential drawbacks of each approach before deciding on the best solution for your application. As we have seen, Transactional Outbox is not always necessary.\n","wordCount":"2268","inLanguage":"en","datePublished":"2023-02-04T00:00:00Z","dateModified":"2023-02-04T00:00:00Z","author":{"@type":"Person","name":"Nejc Korasa"},"mainEntityOfPage":{"@type":"WebPage","@id":"https://nejckorasa.github.io/posts/idempotent-kafka-procesing/"},"publisher":{"@type":"Organization","name":"Nejc Korasa","logo":{"@type":"ImageObject","url":"https://nejckorasa.github.io/favicon.ico"}}}</script></head><body id=top><script>localStorage.getItem("pref-theme")==="dark"?document.body.classList.add("dark"):localStorage.getItem("pref-theme")==="light"?document.body.classList.remove("dark"):window.matchMedia("(prefers-color-scheme: dark)").matches&&document.body.classList.add("dark")</script><header class=header><nav class=nav><div class=logo><a href=https://nejckorasa.github.io accesskey=h title="Nejc Korasa (Alt + H)">Nejc Korasa</a><div class=logo-switches><button id=theme-toggle accesskey=t title="(Alt + T)"><svg id="moon" xmlns="http://www.w3.org/2000/svg" width="24" height="18" viewBox="0 0 24 24" fill="none" stroke="currentcolor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><path d="M21 12.79A9 9 0 1111.21 3 7 7 0 0021 12.79z"/></svg><svg id="sun" xmlns="http://www.w3.org/2000/svg" width="24" height="18" viewBox="0 0 24 24" fill="none" stroke="currentcolor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><circle cx="12" cy="12" r="5"/><line x1="12" y1="1" x2="12" y2="3"/><line x1="12" y1="21" x2="12" y2="23"/><line x1="4.22" y1="4.22" x2="5.64" y2="5.64"/><line x1="18.36" y1="18.36" x2="19.78" y2="19.78"/><line x1="1" y1="12" x2="3" y2="12"/><line x1="21" y1="12" x2="23" y2="12"/><line x1="4.22" y1="19.78" x2="5.64" y2="18.36"/><line x1="18.36" y1="5.64" x2="19.78" y2="4.22"/></svg></button></div></div><ul id=menu><li><a href=https://nejckorasa.github.io/archives/ title=Archive><span>Archive</span></a></li><li><a href=https://nejckorasa.github.io/categories/ title=Categories><span>Categories</span></a></li><li><a href=https://nejckorasa.github.io/tags/ title=Tags><span>Tags</span></a></li><li><a href=https://nejckorasa.github.io/search/ title="Search (Alt + /)" accesskey=/><span>Search</span></a></li></ul></nav></header><main class=main><article class=post-single><header class=post-header><div class=breadcrumbs><a href=https://nejckorasa.github.io>Home</a>&nbsp;»&nbsp;<a href=https://nejckorasa.github.io/posts/>Posts</a></div><h1 class=post-title>Idempotent Processing with Kafka</h1><div class=post-meta><span title='2023-02-04 00:00:00 +0000 UTC'>February 4, 2023</span>&nbsp;·&nbsp;11 min&nbsp;·&nbsp;2268 words&nbsp;·&nbsp;Nejc Korasa</div></header><div class=post-content><ul><li><a href=#duplicate-messages-are-inevitable>Duplicate Messages are Inevitable</a></li><li><a href=#understanding-the-intricacies-of-exactly-once-semantics-in-kafka>Understanding the Intricacies of exactly-once semantics in Kafka</a></li><li><a href=#achieving-idempotent-processing-with-kafka>Achieving Idempotent Processing with Kafka</a><ul><li><a href=#idempotent-consumer-pattern>Idempotent Consumer Pattern</a></li><li><a href=#ordering-of-messages>Ordering of Messages</a></li><li><a href=#retry-handling>Retry Handling</a></li><li><a href=#idempotent-processing-and-external-side-effects>Idempotent Processing and External Side Effects</a></li></ul></li><li><a href=#publishing-output-messages-to-kafka-and-maintaining-data-consistency>Publishing Output Messages to Kafka and Maintaining Data Consistency</a><ul><li><a href=#the-simplest-solution>The Simplest Solution</a></li><li><a href=#transactional-outbox-pattern>Transactional Outbox Pattern</a></li><li><a href=#without-transactional-outbox>Without Transactional Outbox</a></li></ul></li><li><a href=#how-it-compares-to-synchronous-rest-apis>How it compares to Synchronous REST APIs</a></li><li><a href=#final-thoughts>Final Thoughts</a></li></ul><h2 id=duplicate-messages-are-inevitable>Duplicate Messages are Inevitable<a hidden class=anchor aria-hidden=true href=#duplicate-messages-are-inevitable>#</a></h2><p>Duplicate messages are an inherent aspect of message-based systems and can occur for various reasons. In the context of Kafka, it is essential to ensure that your application is able to handle these duplicates effectively. As a Kafka consumer, there are several scenarios that can lead to the consumption of duplicate messages:</p><ul><li>There can be an actual duplicate message in the kafka topic you are consuming from. The consumer is reading 2 different messages that should be treated as duplicates.</li><li>You consume the same message more than once due to various error scenarios that can happen, either in your application, or in the communication with a Kafka broker.</li></ul><p>To ensure the idempotent processing and handle these scenarios, it&rsquo;s important to have a proper strategy to detect and handle duplicate messages.</p><h2 id=understanding-the-intricacies-of-exactly-once-semantics-in-kafka>Understanding the Intricacies of exactly-once semantics in Kafka<a hidden class=anchor aria-hidden=true href=#understanding-the-intricacies-of-exactly-once-semantics-in-kafka>#</a></h2><p>Kafka offers different message delivery guarantees, or <a href=https://kafka.apache.org/documentation/#semantics>delivery semantics</a>, between producers and consumers, namely <em>at-least-once</em>, <em>at-most-once</em> and <em>exactly-once</em>.</p><p>Exactly-once would seem like an obvious choice to guard against duplicate messages, but it not that simple and the devil is in the details. Confluent has spent a lot of resources to deliver exactly-once delivery guarantee, and you can read <a href=https://www.confluent.io/en-gb/blog/exactly-once-semantics-are-possible-heres-how-apache-kafka-does-it/>here</a> on how it works in detail. It requires enabling specific Kafka features (i.e. Idempotent Producer and Kafka Transactions).</p><p>First of all, it is only applicable in an application that consumes a Kafka message, does some processing, and writes a resulting message to a Kafka topic. Exactly-once messaging semantics ensures the <strong>combined</strong> outcome of multiple steps will happen exactly-once. Key word here is combined. A message will be consumed, processed, and resulting messages produced, exactly-once.</p><p>Critical points to understand about exactly-once delivery are:</p><ul><li><p><strong>All other actions occurring as part of the processing can still happen multiple times, if the original message is re-consumed.</strong></p><p>The guarantee only covers resulting messages from the processing to be written exactly once, so downstream transaction aware consumers will not have to handle duplicates. Hence, each individual action (internal or external) still needs to be processed in an idempotent fashion to ensure real end-to-end exactly once processing. Application may need to, for example, perform REST calls to other applications, write to the database etc.</p></li><li><p><strong>All participating consumers and producers need to be configured correctly.</strong></p><p>Kafka exactly-once semantics is achieved by enabling <a href=https://www.conduktor.io/kafka/idempotent-kafka-producer>Kafka Idempotent Producers</a> and <a href=https://www.confluent.io/en-gb/blog/transactions-apache-kafka/>Kafka Transactions</a> in <strong>all</strong> consumers and producers involved. That includes the upstream producer and downstream consumers from the perspective of you application.</p><p>If you are using Event-driven architecture to implement inter-service communication in your system, it is likely that you will consume messages you don&rsquo;t control, or own. Kafka topic is just your asynchronous API you are a consumer of. The topic and the producer can be owned by another team or a 3rd party. Similarly, you may not control downstream consumers.</p><p>To add to the first point, outbound messages can still be written to the topic multiple times before being successfully committed, it is the responsibility of any downstream consumers to only read committed messages (i.e. be transaction aware) in order to meet the exactly-once guarantee.</p></li><li><p><strong>it comes with a performance impact.</strong></p><p>Exactly-once delivery comes with a performance overhead. There are simply more steps involved for a single kafka message to be processed (e.g. Kafka performs a two-phase commit to support transactions) and that results in lower throughput and increased latency.</p></li></ul><p>In practice, it&rsquo;s often much simpler, and more common, to settle for at-least-once semantic and just de-duplicate messages on the consumer side. Especially in cases where application processing is either expensive, or more involved and consists of other actions (e.g. REST calls and DB writes). It&rsquo;s important to remember there is a transaction boundary gap between a DB transaction and a Kafka transaction, more on that later.</p><h2 id=achieving-idempotent-processing-with-kafka>Achieving Idempotent Processing with Kafka<a hidden class=anchor aria-hidden=true href=#achieving-idempotent-processing-with-kafka>#</a></h2><p>This will depend on the nature of processing, and on the shape of the output. To enable idempotent processing, the trigger for the processing - whether it be a Kafka message or an HTTP request - must carry a unique identifier (i.e. an idempotency key).</p><h3 id=idempotent-consumer-pattern>Idempotent Consumer Pattern<a hidden class=anchor aria-hidden=true href=#idempotent-consumer-pattern>#</a></h3><p>An <a href=https://microservices.io/patterns/communication-style/idempotent-consumer.html>Idempotent Consumer Pattern</a> ensures that a Kafka consumer can handle duplicate messages correctly. Consumer can be made idempotent by recording in the database the IDs of the messages that it has processed successfully. When processing a message, a consumer can detect and discard duplicates by querying the database. To illustrate that with pseudocode:</p><div class=highlight><pre tabindex=0 class=chroma><code class=language-java data-lang=java><span class=line><span class=cl><span class=n>var</span> <span class=n>kafkaMessage</span> <span class=o>=</span> <span class=n>kafkaConsumer</span><span class=o>.</span><span class=na>consume</span><span class=o>();</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=k>if</span> <span class=o>(!</span><span class=n>database</span><span class=o>.</span><span class=na>isDuplicate</span><span class=o>(</span><span class=n>kafkaMessage</span><span class=o>))</span> <span class=o>{</span>
</span></span><span class=line><span class=cl>    <span class=n>var</span> <span class=n>result</span> <span class=o>=</span> <span class=n>processMessageIdempotently</span><span class=o>(</span><span class=n>kafkaMessage</span><span class=o>);</span>
</span></span><span class=line><span class=cl>    <span class=n>database</span><span class=o>.</span><span class=na>updateAndRecordProcessed</span><span class=o>(</span><span class=n>result</span><span class=o>);</span>
</span></span><span class=line><span class=cl><span class=o>}</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=n>kafkaConsumer</span><span class=o>.</span><span class=na>commitOffset</span><span class=o>(</span><span class=n>kafkaMessage</span><span class=o>);</span>
</span></span></code></pre></div><h3 id=ordering-of-messages>Ordering of Messages<a hidden class=anchor aria-hidden=true href=#ordering-of-messages>#</a></h3><p>Choosing an appropriate topic key can help to ensure ordering guarantees within the same Kafka partition. For example, if messages are being processed in the context of a customer, using a customer ID as the topic key will ensure that messages for any individual customer will always be processed in the correct order.</p><h3 id=retry-handling>Retry Handling<a hidden class=anchor aria-hidden=true href=#retry-handling>#</a></h3><p>Kafka&rsquo;s offset commits can be used to create a &ldquo;transaction boundary&rdquo; (not to be confused with Kafka transactions mentioned before) for retrying message processing in case of failure. The same message can then be consumed again until the consumer offset is committed. Retry handling is a complex topic and various strategies can be employed depending on the specific requirements of the application. Confluent has written about <a href=https://www.confluent.io/en-gb/blog/error-handling-patterns-in-kafka/>Kafka Error Handling Patterns</a> that can be used to handle retries in a Kafka-based application.</p><h3 id=idempotent-processing-and-external-side-effects>Idempotent Processing and External Side Effects<a hidden class=anchor aria-hidden=true href=#idempotent-processing-and-external-side-effects>#</a></h3><p>As mentioned before, there is no exactly-once guarantee for application processing. All actions occurring as part of the processing, and all external side effects, can still happen multiple times. For example, in case of REST calls to other services, calls themselves need to be idempotent, and the same idempotency key needs to be relayed over to those calls. Similarly, all database writes need to be idempotent.</p><h2 id=publishing-output-messages-to-kafka-and-maintaining-data-consistency>Publishing Output Messages to Kafka and Maintaining Data Consistency<a hidden class=anchor aria-hidden=true href=#publishing-output-messages-to-kafka-and-maintaining-data-consistency>#</a></h2><p>When it comes to publishing messages back to Kafka after processing is complete, the complexity increases. In a Microservices architecture, services along with updating their own local data store they often need to notify other services within the organization of changes that have occurred. This is where event-driven architecture shines, allowing individual services to publish changes as events to a Kafka topic that can be consumed by other services. But how can this be achieved in a way that ensures data consistency and enables idempotent processing?</p><h3 id=the-simplest-solution>The Simplest Solution<a hidden class=anchor aria-hidden=true href=#the-simplest-solution>#</a></h3><p>Consuming from Kafka has a built-in retry mechanism. If the processing is naturally idempotent, deterministic, and does not interact with other services (i.e. all its state resides in Kafka), then the solution can be relatively simple:</p><div class=highlight><pre tabindex=0 class=chroma><code class=language-java data-lang=java><span class=line><span class=cl><span class=n>var</span> <span class=n>kafkaMessage</span> <span class=o>=</span> <span class=n>kafkaConsumer</span><span class=o>.</span><span class=na>consume</span><span class=o>();</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=n>var</span> <span class=n>result</span> <span class=o>=</span> <span class=n>processMessageIdempotently</span><span class=o>(</span><span class=n>kafkaMessage</span><span class=o>);</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=n>var</span> <span class=n>kafkaOutputMessage</span> <span class=o>=</span> <span class=n>result</span><span class=o>.</span><span class=na>toKafkaOutputMessage</span><span class=o>();</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=n>kafkaProducer</span><span class=o>.</span><span class=na>produceAndFlush</span><span class=o>(</span><span class=n>kafkaOutputMessage</span><span class=o>);</span>
</span></span><span class=line><span class=cl><span class=n>kafkaConsumer</span><span class=o>.</span><span class=na>commitOffset</span><span class=o>(</span><span class=n>kafkaMessage</span><span class=o>);</span>
</span></span></code></pre></div><ol><li>Consume the message from a Kafka topic.</li><li>Process the message.</li><li>Publish the resulting message to a Kafka topic.</li><li>Commit the consumer offset.</li></ol><p>This approach ensures data consistency and enables idempotent processing. It guarantees that at least one published message is produced for every consumed message.</p><p>To ensure at least-once delivery of published messages, it&rsquo;s also necessary to ensure that the message is <em>actually</em> sent to the Kafka broker and that the Kafka producer has flushed its outgoing message queue.</p><h3 id=transactional-outbox-pattern>Transactional Outbox Pattern<a hidden class=anchor aria-hidden=true href=#transactional-outbox-pattern>#</a></h3><p>Another approach is to utilize <a href=https://microservices.io/patterns/data/transactional-outbox.html>Transactional Outbox Pattern</a> which fills the gap between the database and Kafka transaction boundary by atomically updating both within the database transaction. The reason being that it is not possible to have a single transaction that spans the application’s database as well as Kafka.</p><p>One possible implementation of this pattern is to have an “<em>outbox</em>” table and instead of publishing resulting messages directly to Kafka, the messages are written to the outbox table in a compatible format (e.g. <a href=https://www.confluent.io/en-gb/blog/avro-kafka-data/>Avro</a>).</p><div class=highlight><pre tabindex=0 class=chroma><code class=language-java data-lang=java><span class=line><span class=cl><span class=n>var</span> <span class=n>kafkaMessage</span> <span class=o>=</span> <span class=n>kafkaConsumer</span><span class=o>.</span><span class=na>consume</span><span class=o>();</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=k>if</span> <span class=o>(!</span><span class=n>database</span><span class=o>.</span><span class=na>isDuplicate</span><span class=o>(</span><span class=n>kafkaMessage</span><span class=o>))</span> <span class=o>{</span>
</span></span><span class=line><span class=cl>    <span class=n>var</span> <span class=n>result</span> <span class=o>=</span> <span class=n>processMessageIdempotently</span><span class=o>(</span><span class=n>kafkaMessage</span><span class=o>);</span>
</span></span><span class=line><span class=cl>    
</span></span><span class=line><span class=cl>    <span class=n>var</span> <span class=n>transaction</span> <span class=o>=</span> <span class=n>database</span><span class=o>.</span><span class=na>startTransaction</span><span class=o>();</span>
</span></span><span class=line><span class=cl>    <span class=n>database</span><span class=o>.</span><span class=na>updateAndRecordProcessed</span><span class=o>(</span><span class=n>result</span><span class=o>);</span>
</span></span><span class=line><span class=cl>    <span class=n>database</span><span class=o>.</span><span class=na>writeOutbox</span><span class=o>(</span><span class=n>result</span><span class=o>);</span>
</span></span><span class=line><span class=cl>    <span class=n>transaction</span><span class=o>.</span><span class=na>commit</span><span class=o>();</span>
</span></span><span class=line><span class=cl><span class=o>}</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=n>kafkaConsumer</span><span class=o>.</span><span class=na>commitOffset</span><span class=o>(</span><span class=n>kafkaMessage</span><span class=o>);</span>
</span></span></code></pre></div><p>However, this pattern comes with additional complexity. The message must not only be written to the database but also published to Kafka. This can be implemented by a separate message relay service that continuously polls the database for new outbox messages, publishes them to Kafka, and marks them as processed. However, this approach has several drawbacks:</p><ul><li>Increased load on the database: Frequently polling the database can cause a high level of read traffic, which can lead to increased load on the database and potentially slow down other processes that are trying to access it.</li><li>Latency: Depending on the interval at which the database is polled, there may be a significant delay between when a message is added to the outbox and when it is published to Kafka.</li><li>Scalability: If the number of messages to be published to Kafka increases, the rate of polling will need to be increased, which can further increase the load on the database and make the system less scalable.</li><li>Schema incompatibility issues: If the message schema is incompatible with a destination topic, application processing will succeed, but the poller could be unable to publish a message to Kafka. The risk of this can be minimized by verifying Avro schema with a schema registry before writing to the outbox table.</li><li>Ordering of messages: Poller needs to ensure the order of messages written to the outbox tables is retained when publishing to Kafka.</li><li>Missed messages: There is a chance that a message is not picked up by the poller and not published to Kafka.</li><li>Lack of real-time: The messages are not published to kafka in real-time as it depends on the polling interval.</li></ul><p>A better approach is to utilize <a href="https://learn.microsoft.com/en-us/sql/relational-databases/track-changes/about-change-data-capture-sql-server?view=sql-server-ver16">CDC (change data capture)</a> if your database supports it. You can use <a href=https://debezium.io>Debezium</a> and <a href=https://docs.confluent.io/platform/current/connect/index.html>Kafka Connect</a> to integrate CDC with a PostgresDB for example. That way, the database and Kafka stay in sync, and you don&rsquo;t have to deal with the drawbacks of database polling.</p><h3 id=without-transactional-outbox>Without Transactional Outbox<a hidden class=anchor aria-hidden=true href=#without-transactional-outbox>#</a></h3><p>However, even with the use of CDC, that will still result in another component that needs to be managed and monitored, and another possible point of failure. In certain situations it is easier to avoid the Transactional Outbox Pattern and handle writes to Kafka within the application. That can be achieved by combining the first simple solution explained above with the Idempotent Consumer pattern:</p><div class=highlight><pre tabindex=0 class=chroma><code class=language-java data-lang=java><span class=line><span class=cl><span class=n>var</span> <span class=n>kafkaMessage</span> <span class=o>=</span> <span class=n>consumeKafkaMessage</span><span class=o>(</span><span class=n>kafkaClient</span><span class=o>);</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=k>if</span> <span class=o>(!</span><span class=n>database</span><span class=o>.</span><span class=na>isDuplicate</span><span class=o>(</span><span class=n>kafkaMessage</span><span class=o>))</span> <span class=o>{</span>
</span></span><span class=line><span class=cl>    <span class=n>result</span> <span class=o>=</span> <span class=n>processMessageIdempotently</span><span class=o>(</span><span class=n>kafkaMessage</span><span class=o>);</span>
</span></span><span class=line><span class=cl>    <span class=n>database</span><span class=o>.</span><span class=na>updateAndRecordProcessed</span><span class=o>(</span><span class=n>result</span><span class=o>);</span>
</span></span><span class=line><span class=cl><span class=o>}</span> <span class=k>else</span> <span class=o>{</span>
</span></span><span class=line><span class=cl>    <span class=n>result</span> <span class=o>=</span> <span class=n>database</span><span class=o>.</span><span class=na>readResult</span><span class=o>(</span><span class=n>kafkaMessage</span><span class=o>);</span>
</span></span><span class=line><span class=cl><span class=o>}</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=n>var</span> <span class=n>kafkaOutputMessage</span> <span class=o>=</span> <span class=n>result</span><span class=o>.</span><span class=na>toKafkaOutputMessage</span><span class=o>();</span>
</span></span><span class=line><span class=cl><span class=n>kafkaProducer</span><span class=o>.</span><span class=na>produceAndFlush</span><span class=o>(</span><span class=n>kafkaOutputMessage</span><span class=o>);</span>
</span></span><span class=line><span class=cl><span class=n>kafkaConsumer</span><span class=o>.</span><span class=na>commitOffset</span><span class=o>(</span><span class=n>kafkaMessage</span><span class=o>);</span>
</span></span></code></pre></div><ol><li>Consume the message from a Kafka topic.</li><li>Consult the database to confirm the message has not been previously processed.
If it has, read the stored result and proceed to step 5.</li><li>Process the message, taking care to handle any external actions in an idempotent manner.</li><li>Write results to the database and mark the message as successfully processed.</li><li>Publish the resulting message to a Kafka topic.</li><li>Commit the consumer offset.</li></ol><p>The approach outlined above combines the use of the Idempotent Consumer pattern with direct publishing to Kafka, resulting in a streamlined solution for handling duplicate messages.</p><p>Additionally, by eliminating the need for an intermediate &ldquo;<em>outbox</em>&rdquo; table, this approach reduces the number of components that need to be managed and monitored, resulting in a simpler overall architecture.</p><p>Furthermore, it also benefits from reduced latency in message publishing as it avoids the added step of writing to a database before publishing to Kafka.</p><p>This approach has some downsides to consider:</p><ul><li>It might simplify overall architecture but it increases the complexity of processing within the application.</li><li>The addition of a Kafka publish step can cause a performance overhead and prolong overall processing time.</li></ul><h2 id=how-it-compares-to-synchronous-rest-apis>How it compares to Synchronous REST APIs<a hidden class=anchor aria-hidden=true href=#how-it-compares-to-synchronous-rest-apis>#</a></h2><p>Similarly to the Idempotent Consumer Pattern, in case of a REST API, received message IDs could also be tracked in a database to handle idempotency. However, there are drawbacks to using REST call as a trigger for processing, namely:</p><ul><li>The retry strategy is out of the control of the application, and the caller is responsible for retrying the operation. That makes it more susceptible to failure scenarios and inconsistent states.</li><li>There is no ordering guarantee when responding to HTTP calls, and additional care must be taken to avoid certain race conditions during processing.</li></ul><p>Publishing output messages to Kafka in a way that maintains data consistency can be achieved by using <a href=https://microservices.io/patterns/data/transactional-outbox.html>Transactional Outbox Pattern</a> to atomically update the database and publish a message to Kafka.</p><h2 id=final-thoughts>Final Thoughts<a hidden class=anchor aria-hidden=true href=#final-thoughts>#</a></h2><p>Kafka is an ideal platform for implementing idempotent processing in your application, and it offers several key advantages over traditional synchronous processing methods such as REST APIs. Its built-in retry mechanism and ordering guarantees are essential for ensuring idempotence and maintaining data consistency in the presence of failures.</p><p>When it comes to message delivery guarantees, the exactly-once semantics offered by Kafka can be a powerful tool to guard against duplicate messages. However, it&rsquo;s important to understand the intricacies of this feature, the requirements for its implementation, and its limitations. Additionally, the performance impact and complexity of exactly-once semantics should be taken into consideration.</p><p>Achieving idempotent processing requires a thorough understanding of the triggers, actions, and outputs of the processing. Different approaches such as <a href=https://microservices.io/patterns/communication-style/idempotent-consumer.html>Idempotent Consumer Pattern</a> and <a href=https://microservices.io/patterns/data/transactional-outbox.html>Transactional Outbox Pattern</a> can be used to ensure that messages are processed correctly and that data consistency is maintained. It&rsquo;s important to weigh the complexity and potential drawbacks of each approach before deciding on the best solution for your application. As we have seen, Transactional Outbox is not always necessary.</p></div><footer class=post-footer><ul class=post-tags><li><a href=https://nejckorasa.github.io/tags/kafka/>Kafka</a></li><li><a href=https://nejckorasa.github.io/tags/idempotency/>Idempotency</a></li><li><a href=https://nejckorasa.github.io/tags/software-architecture/>Software Architecture</a></li><li><a href=https://nejckorasa.github.io/tags/event-driven-architecture/>Event Driven Architecture</a></li><li><a href=https://nejckorasa.github.io/tags/asynchronous-processing/>Asynchronous Processing</a></li><li><a href=https://nejckorasa.github.io/tags/transactional-outbox/>Transactional Outbox</a></li></ul><nav class=paginav><a class=next href=https://nejckorasa.github.io/posts/microservice-testing/><span class=title>Next »</span><br><span>Avoid Tight Coupling of Tests to Implementation Details</span></a></nav><div class=share-buttons><a target=_blank rel="noopener noreferrer" aria-label="share Idempotent Processing with Kafka on twitter" href="https://twitter.com/intent/tweet/?text=Idempotent%20Processing%20with%20Kafka&url=https%3a%2f%2fnejckorasa.github.io%2fposts%2fidempotent-kafka-procesing%2f&hashtags=Kafka%2cIdempotency%2cSoftwareArchitecture%2cEventDrivenArchitecture%2cAsynchronousProcessing%2cTransactionalOutbox"><svg viewBox="0 0 512 512" height="30" width="30" fill="currentcolor"><path d="M449.446.0C483.971.0 512 28.03 512 62.554v386.892C512 483.97 483.97 512 449.446 512H62.554c-34.524.0-62.554-28.03-62.554-62.554V62.554c0-34.524 28.029-62.554 62.554-62.554h386.892zM195.519 424.544c135.939.0 210.268-112.643 210.268-210.268.0-3.218.0-6.437-.153-9.502 14.406-10.421 26.973-23.448 36.935-38.314-13.18 5.824-27.433 9.809-42.452 11.648 15.326-9.196 26.973-23.602 32.49-40.92-14.252 8.429-30.038 14.56-46.896 17.931-13.487-14.406-32.644-23.295-53.946-23.295-40.767.0-73.87 33.104-73.87 73.87.0 5.824.613 11.494 1.992 16.858-61.456-3.065-115.862-32.49-152.337-77.241-6.284 10.881-9.962 23.601-9.962 37.088.0 25.594 13.027 48.276 32.95 61.456-12.107-.307-23.448-3.678-33.41-9.196v.92c0 35.862 25.441 65.594 59.311 72.49-6.13 1.686-12.72 2.606-19.464 2.606-4.751.0-9.348-.46-13.946-1.38 9.349 29.426 36.628 50.728 68.965 51.341-25.287 19.771-57.164 31.571-91.8 31.571-5.977.0-11.801-.306-17.625-1.073 32.337 21.15 71.264 33.41 112.95 33.41z"/></svg></a><a target=_blank rel="noopener noreferrer" aria-label="share Idempotent Processing with Kafka on linkedin" href="https://www.linkedin.com/shareArticle?mini=true&url=https%3a%2f%2fnejckorasa.github.io%2fposts%2fidempotent-kafka-procesing%2f&title=Idempotent%20Processing%20with%20Kafka&summary=Idempotent%20Processing%20with%20Kafka&source=https%3a%2f%2fnejckorasa.github.io%2fposts%2fidempotent-kafka-procesing%2f"><svg viewBox="0 0 512 512" height="30" width="30" fill="currentcolor"><path d="M449.446.0C483.971.0 512 28.03 512 62.554v386.892C512 483.97 483.97 512 449.446 512H62.554c-34.524.0-62.554-28.03-62.554-62.554V62.554c0-34.524 28.029-62.554 62.554-62.554h386.892zM160.461 423.278V197.561h-75.04v225.717h75.04zm270.539.0V293.839c0-69.333-37.018-101.586-86.381-101.586-39.804.0-57.634 21.891-67.617 37.266v-31.958h-75.021c.995 21.181.0 225.717.0 225.717h75.02V297.222c0-6.748.486-13.492 2.474-18.315 5.414-13.475 17.767-27.434 38.494-27.434 27.135.0 38.007 20.707 38.007 51.037v120.768H431zM123.448 88.722C97.774 88.722 81 105.601 81 127.724c0 21.658 16.264 39.002 41.455 39.002h.484c26.165.0 42.452-17.344 42.452-39.002-.485-22.092-16.241-38.954-41.943-39.002z"/></svg></a><a target=_blank rel="noopener noreferrer" aria-label="share Idempotent Processing with Kafka on reddit" href="https://reddit.com/submit?url=https%3a%2f%2fnejckorasa.github.io%2fposts%2fidempotent-kafka-procesing%2f&title=Idempotent%20Processing%20with%20Kafka"><svg viewBox="0 0 512 512" height="30" width="30" fill="currentcolor"><path d="M449.446.0C483.971.0 512 28.03 512 62.554v386.892C512 483.97 483.97 512 449.446 512H62.554c-34.524.0-62.554-28.03-62.554-62.554V62.554c0-34.524 28.029-62.554 62.554-62.554h386.892zM446 265.638c0-22.964-18.616-41.58-41.58-41.58-11.211.0-21.361 4.457-28.841 11.666-28.424-20.508-67.586-33.757-111.204-35.278l18.941-89.121 61.884 13.157c.756 15.734 13.642 28.29 29.56 28.29 16.407.0 29.706-13.299 29.706-29.701.0-16.403-13.299-29.702-29.706-29.702-11.666.0-21.657 6.792-26.515 16.578l-69.105-14.69c-1.922-.418-3.939-.042-5.585 1.036-1.658 1.073-2.811 2.761-3.224 4.686l-21.152 99.438c-44.258 1.228-84.046 14.494-112.837 35.232-7.468-7.164-17.589-11.591-28.757-11.591-22.965.0-41.585 18.616-41.585 41.58.0 16.896 10.095 31.41 24.568 37.918-.639 4.135-.99 8.328-.99 12.576.0 63.977 74.469 115.836 166.33 115.836s166.334-51.859 166.334-115.836c0-4.218-.347-8.387-.977-12.493 14.564-6.47 24.735-21.034 24.735-38.001zM326.526 373.831c-20.27 20.241-59.115 21.816-70.534 21.816-11.428.0-50.277-1.575-70.522-21.82-3.007-3.008-3.007-7.882.0-10.889 3.003-2.999 7.882-3.003 10.885.0 12.777 12.781 40.11 17.317 59.637 17.317 19.522.0 46.86-4.536 59.657-17.321 3.016-2.999 7.886-2.995 10.885.008 3.008 3.011 3.003 7.882-.008 10.889zm-5.23-48.781c-16.373.0-29.701-13.324-29.701-29.698.0-16.381 13.328-29.714 29.701-29.714 16.378.0 29.706 13.333 29.706 29.714.0 16.374-13.328 29.698-29.706 29.698zM160.91 295.348c0-16.381 13.328-29.71 29.714-29.71 16.369.0 29.689 13.329 29.689 29.71.0 16.373-13.32 29.693-29.689 29.693-16.386.0-29.714-13.32-29.714-29.693z"/></svg></a><a target=_blank rel="noopener noreferrer" aria-label="share Idempotent Processing with Kafka on facebook" href="https://facebook.com/sharer/sharer.php?u=https%3a%2f%2fnejckorasa.github.io%2fposts%2fidempotent-kafka-procesing%2f"><svg viewBox="0 0 512 512" height="30" width="30" fill="currentcolor"><path d="M449.446.0C483.971.0 512 28.03 512 62.554v386.892C512 483.97 483.97 512 449.446 512H342.978V319.085h66.6l12.672-82.621h-79.272v-53.617c0-22.603 11.073-44.636 46.58-44.636H425.6v-70.34s-32.71-5.582-63.982-5.582c-65.288.0-107.96 39.569-107.96 111.204v62.971h-72.573v82.621h72.573V512h-191.104c-34.524.0-62.554-28.03-62.554-62.554V62.554c0-34.524 28.029-62.554 62.554-62.554h386.892z"/></svg></a><a target=_blank rel="noopener noreferrer" aria-label="share Idempotent Processing with Kafka on whatsapp" href="https://api.whatsapp.com/send?text=Idempotent%20Processing%20with%20Kafka%20-%20https%3a%2f%2fnejckorasa.github.io%2fposts%2fidempotent-kafka-procesing%2f"><svg viewBox="0 0 512 512" height="30" width="30" fill="currentcolor"><path d="M449.446.0C483.971.0 512 28.03 512 62.554v386.892C512 483.97 483.97 512 449.446 512H62.554c-34.524.0-62.554-28.03-62.554-62.554V62.554c0-34.524 28.029-62.554 62.554-62.554h386.892zm-58.673 127.703c-33.842-33.881-78.847-52.548-126.798-52.568-98.799.0-179.21 80.405-179.249 179.234-.013 31.593 8.241 62.428 23.927 89.612l-25.429 92.884 95.021-24.925c26.181 14.28 55.659 21.807 85.658 21.816h.074c98.789.0 179.206-80.413 179.247-179.243.018-47.895-18.61-92.93-52.451-126.81zM263.976 403.485h-.06c-26.734-.01-52.954-7.193-75.828-20.767l-5.441-3.229-56.386 14.792 15.05-54.977-3.542-5.637c-14.913-23.72-22.791-51.136-22.779-79.287.033-82.142 66.867-148.971 149.046-148.971 39.793.014 77.199 15.531 105.329 43.692 28.128 28.16 43.609 65.592 43.594 105.4-.034 82.149-66.866 148.983-148.983 148.984zm81.721-111.581c-4.479-2.242-26.499-13.075-30.604-14.571-4.105-1.495-7.091-2.241-10.077 2.241-2.986 4.483-11.569 14.572-14.182 17.562-2.612 2.988-5.225 3.364-9.703 1.12-4.479-2.241-18.91-6.97-36.017-22.23C231.8 264.15 222.81 249.484 220.198 245s-.279-6.908 1.963-9.14c2.016-2.007 4.48-5.232 6.719-7.847 2.24-2.615 2.986-4.484 4.479-7.472 1.493-2.99.747-5.604-.374-7.846-1.119-2.241-10.077-24.288-13.809-33.256-3.635-8.733-7.327-7.55-10.077-7.688-2.609-.13-5.598-.158-8.583-.158-2.986.0-7.839 1.121-11.944 5.604-4.105 4.484-15.675 15.32-15.675 37.364.0 22.046 16.048 43.342 18.287 46.332 2.24 2.99 31.582 48.227 76.511 67.627 10.685 4.615 19.028 7.371 25.533 9.434 10.728 3.41 20.492 2.929 28.209 1.775 8.605-1.285 26.499-10.833 30.231-21.295 3.732-10.464 3.732-19.431 2.612-21.298-1.119-1.869-4.105-2.99-8.583-5.232z"/></svg></a><a target=_blank rel="noopener noreferrer" aria-label="share Idempotent Processing with Kafka on telegram" href="https://telegram.me/share/url?text=Idempotent%20Processing%20with%20Kafka&url=https%3a%2f%2fnejckorasa.github.io%2fposts%2fidempotent-kafka-procesing%2f"><svg viewBox="2 2 28 28" height="30" width="30" fill="currentcolor"><path d="M26.49 29.86H5.5a3.37 3.37.0 01-2.47-1 3.35 3.35.0 01-1-2.47V5.48A3.36 3.36.0 013 3 3.37 3.37.0 015.5 2h21A3.38 3.38.0 0129 3a3.36 3.36.0 011 2.46V26.37a3.35 3.35.0 01-1 2.47 3.38 3.38.0 01-2.51 1.02zm-5.38-6.71a.79.79.0 00.85-.66L24.73 9.24a.55.55.0 00-.18-.46.62.62.0 00-.41-.17q-.08.0-16.53 6.11a.59.59.0 00-.41.59.57.57.0 00.43.52l4 1.24 1.61 4.83a.62.62.0 00.63.43.56.56.0 00.4-.17L16.54 20l4.09 3A.9.9.0 0021.11 23.15zM13.8 20.71l-1.21-4q8.72-5.55 8.78-5.55c.15.0.23.0.23.16a.18.18.0 010 .06s-2.51 2.3-7.52 6.8z"/></svg></a></div></footer><script src=https://utteranc.es/client.js repo=nejckorasa/nejckorasa.github.io issue-term=pathname label=Comment theme=preferred-color-scheme crossorigin=anonymous async></script></article></main><footer class=footer><span>&copy; 2023 <a href=https://nejckorasa.github.io>Nejc Korasa</a></span>
<span>Powered by
<a href=https://gohugo.io/ rel="noopener noreferrer" target=_blank>Hugo</a> &
        <a href=https://github.com/adityatelange/hugo-PaperMod/ rel=noopener target=_blank>PaperMod</a></span></footer><a href=#top aria-label="go to top" title="Go to Top (Alt + G)" class=top-link id=top-link accesskey=g><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 12 6" fill="currentcolor"><path d="M12 6H0l6-6z"/></svg></a><script>let menu=document.getElementById("menu");menu&&(menu.scrollLeft=localStorage.getItem("menu-scroll-position"),menu.onscroll=function(){localStorage.setItem("menu-scroll-position",menu.scrollLeft)}),document.querySelectorAll('a[href^="#"]').forEach(e=>{e.addEventListener("click",function(e){e.preventDefault();var t=this.getAttribute("href").substr(1);window.matchMedia("(prefers-reduced-motion: reduce)").matches?document.querySelector(`[id='${decodeURIComponent(t)}']`).scrollIntoView():document.querySelector(`[id='${decodeURIComponent(t)}']`).scrollIntoView({behavior:"smooth"}),t==="top"?history.replaceState(null,null," "):history.pushState(null,null,`#${t}`)})})</script><script>var mybutton=document.getElementById("top-link");window.onscroll=function(){document.body.scrollTop>800||document.documentElement.scrollTop>800?(mybutton.style.visibility="visible",mybutton.style.opacity="1"):(mybutton.style.visibility="hidden",mybutton.style.opacity="0")}</script><script>document.getElementById("theme-toggle").addEventListener("click",()=>{document.body.className.includes("dark")?(document.body.classList.remove("dark"),localStorage.setItem("pref-theme","light")):(document.body.classList.add("dark"),localStorage.setItem("pref-theme","dark"))})</script></body></html>